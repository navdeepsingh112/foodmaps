{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc1bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required packages installation commands ready\n",
      "Uncomment the lines above to install packages\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Run this cell first before executing other cells\n",
    "\n",
    "# !pip install unsloth\n",
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install trl\n",
    "# !pip install scikit-learn\n",
    "\n",
    "print(\"Required packages installation commands ready\")\n",
    "print(\"Uncomment the lines above to install packages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6ea7e",
   "metadata": {},
   "source": [
    "# Recipe Extraction Fine-tuning for Gemma Model\n",
    "\n",
    "## Overview\n",
    "This notebook fine-tunes the Gemma-3-270m model to extract structured recipe information from three different input formats:\n",
    "1. **YouTube video transcripts** - Conversational cooking instructions\n",
    "2. **HTML webpages** - Structured HTML recipe pages  \n",
    "3. **Human written text** - Plain text recipe descriptions\n",
    "\n",
    "## Output Format\n",
    "The model outputs recipes in a strict JSON format:\n",
    "```json\n",
    "{\n",
    "  \"recipe_name\": \"Recipe Name\",\n",
    "  \"ingredients\": [\n",
    "    {\"qty\": \"1 cup\", \"name\": \"flour\"}\n",
    "  ],\n",
    "  \"instructions\": [\n",
    "    {\"id\": 1, \"text\": \"Mix ingredients\", \"duration\": 0}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "## Datasets Used\n",
    "1. **Local JSONL**: `cooking_recipes_sample_100.jsonl` (100 samples)\n",
    "2. **RecipeNLG**: HuggingFace dataset `mbien/recipe_nlg` (~1M recipes)\n",
    "3. **OpenRecipes**: HuggingFace dataset `napsternxg/openrecipes-20170107-061401-recipeitems` (~100K recipes)\n",
    "\n",
    "## Training Process\n",
    "1. Load and combine datasets\n",
    "2. Format to ChatML with synthetic input variations\n",
    "3. Apply LoRA adapters to Gemma model\n",
    "4. Fine-tune on combined dataset\n",
    "5. Validate output format compliance\n",
    "6. Test on all three input types\n",
    "\n",
    "## Usage\n",
    "After training, the model can extract recipes from any of the three input formats and return them in the standardized JSON structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b028a757-9a7b-4a8e-b781-6722d5c4f583",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m  Cell In[3], line 1\u001b[0m\n\u001b[0;32m    source .venv/bin/activate\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "source .venv/bin/activate #run in terminal to activate virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e99789-d986-42b3-b153-f49627a1a31e",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02d87b-27ae-4fcc-ba80-aacb6da10fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local JSONL samples: 100\n",
      "Sample format: {'input': 'Hey everyone, today I\\'m gonna show you how to make Oatmeal Chocolate Chip Cookies...', 'output': '{\"recipe_name\": \"Oatmeal Chocolate Chip Cookies\"...}'}\n",
      "\n",
      "Loading RecipeNLG dataset...\n",
      "RecipeNLG samples: 2231142\n",
      "\n",
      "Loading OpenRecipes dataset...\n",
      "OpenRecipes samples: 173278\n",
      "\n",
      "Using 10000 RecipeNLG samples\n",
      "Using 5000 OpenRecipes samples\n",
      "Using 100 local JSONL samples\n"
     ]
    }
   ],
   "source": [
    "#IMPORT RECIPE DATASETS FROM HUGGINGFACE AND LOCAL JSONL\n",
    "from datasets import Dataset, load_dataset\n",
    "import json\n",
    "\n",
    "# Load local JSONL dataset\n",
    "with open('cooking_recipes_sample_100.jsonl', 'r') as f:\n",
    "    local_recipes = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"Local JSONL samples: {len(local_recipes)}\")\n",
    "print(f\"Sample format: {local_recipes[0]}\")\n",
    "\n",
    "# Load RecipeNLG dataset from HuggingFace\n",
    "print(\"\\nLoading RecipeNLG dataset...\")\n",
    "recipenlg_dataset = load_dataset(\"mbien/recipe_nlg\", split=\"train\")\n",
    "print(f\"RecipeNLG samples: {len(recipenlg_dataset)}\")\n",
    "\n",
    "# Load OpenRecipes dataset from HuggingFace  \n",
    "print(\"\\nLoading OpenRecipes dataset...\")\n",
    "openrecipes_dataset = load_dataset(\"napsternxg/openrecipes-20170107-061401-recipeitems\", split=\"train\")\n",
    "print(f\"OpenRecipes samples: {len(openrecipes_dataset)}\")\n",
    "\n",
    "# Use a subset for training (adjust size as needed)\n",
    "recipenlg_subset = recipenlg_dataset.select(range(min(10000, len(recipenlg_dataset))))\n",
    "openrecipes_subset = openrecipes_dataset.select(range(min(5000, len(openrecipes_dataset))))\n",
    "\n",
    "print(f\"\\nUsing {len(recipenlg_subset)} RecipeNLG samples\")\n",
    "print(f\"Using {len(openrecipes_subset)} OpenRecipes samples\")\n",
    "print(f\"Using {len(local_recipes)} local JSONL samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f849f-c8be-4af9-9448-ce6850246daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting local JSONL dataset...\n",
      "Converting RecipeNLG dataset...\n",
      "Converting OpenRecipes dataset...\n",
      "\n",
      "Total training examples: 15100\n",
      "Train samples: 14345\n",
      "Validation samples: 755\n",
      "\n",
      "Sample training example:\n",
      "{'messages': [{'role': 'user', 'content': 'Extract the recipe information...'}, {'role': 'assistant', 'content': '{\"recipe_name\": \"...\"...}'}]}\n"
     ]
    }
   ],
   "source": [
    "#FORMATTING DATASETS TO RECIPE EXTRACTION FORMAT\n",
    "import json\n",
    "import random\n",
    "\n",
    "def format_recipe_output(recipe_data):\n",
    "    \"\"\"Convert recipe data to the standardized output format\"\"\"\n",
    "    output = {\n",
    "        \"recipe_name\": recipe_data.get(\"name\", recipe_data.get(\"title\", \"Unknown Recipe\")),\n",
    "        \"ingredients\": [],\n",
    "        \"instructions\": []\n",
    "    }\n",
    "    \n",
    "    # Format ingredients\n",
    "    ingredients = recipe_data.get(\"ingredients\", [])\n",
    "    if isinstance(ingredients, list):\n",
    "        for ing in ingredients:\n",
    "            if isinstance(ing, dict):\n",
    "                output[\"ingredients\"].append({\n",
    "                    \"qty\": ing.get(\"qty\", ing.get(\"quantity\", \"\")),\n",
    "                    \"name\": ing.get(\"name\", ing.get(\"ingredient\", \"\"))\n",
    "                })\n",
    "            else:\n",
    "                # If it's a string, try to parse it\n",
    "                output[\"ingredients\"].append({\n",
    "                    \"qty\": \"\",\n",
    "                    \"name\": str(ing)\n",
    "                })\n",
    "    \n",
    "    # Format instructions\n",
    "    instructions = recipe_data.get(\"instructions\", recipe_data.get(\"steps\", []))\n",
    "    if isinstance(instructions, str):\n",
    "        # Split string into steps\n",
    "        steps = [s.strip() for s in instructions.split('.') if s.strip()]\n",
    "        for idx, step in enumerate(steps, 1):\n",
    "            output[\"instructions\"].append({\n",
    "                \"id\": idx,\n",
    "                \"text\": step,\n",
    "                \"duration\": 0\n",
    "            })\n",
    "    elif isinstance(instructions, list):\n",
    "        for idx, step in enumerate(instructions, 1):\n",
    "            if isinstance(step, dict):\n",
    "                output[\"instructions\"].append({\n",
    "                    \"id\": idx,\n",
    "                    \"text\": step.get(\"text\", step.get(\"step\", \"\")),\n",
    "                    \"duration\": step.get(\"duration\", 0)\n",
    "                })\n",
    "            else:\n",
    "                output[\"instructions\"].append({\n",
    "                    \"id\": idx,\n",
    "                    \"text\": str(step),\n",
    "                    \"duration\": 0\n",
    "                })\n",
    "    \n",
    "    return json.dumps(output)\n",
    "\n",
    "def convert_to_chatml(examples_list, source_type=\"mixed\"):\n",
    "    \"\"\"Convert recipe data to ChatML format for training\"\"\"\n",
    "    chatml_dataset = []\n",
    "    \n",
    "    for example in examples_list:\n",
    "        # Get input and output\n",
    "        if \"input\" in example and \"output\" in example:\n",
    "            # Already formatted from JSONL\n",
    "            input_text = example[\"input\"]\n",
    "            output_text = example[\"output\"]\n",
    "        else:\n",
    "            # Need to create synthetic input from different sources\n",
    "            input_types = [\"youtube_transcript\", \"html_webpage\", \"human_text\"]\n",
    "            input_type = random.choice(input_types)\n",
    "            \n",
    "            recipe_name = example.get(\"name\", example.get(\"title\", \"Recipe\"))\n",
    "            ingredients = example.get(\"ingredients\", [])\n",
    "            instructions = example.get(\"instructions\", example.get(\"directions\", []))\n",
    "            \n",
    "            # Create different input formats\n",
    "            if input_type == \"youtube_transcript\":\n",
    "                input_text = f\"Hey everyone, today I'm gonna show you how to make {recipe_name}. \"\n",
    "                input_text += \"Okay so first things first, let me gather all the ingredients.\\n\\n\"\n",
    "                for ing in ingredients[:10]:  # Limit ingredients\n",
    "                    if isinstance(ing, dict):\n",
    "                        qty = ing.get(\"qty\", ing.get(\"quantity\", \"\"))\n",
    "                        name = ing.get(\"name\", ing.get(\"ingredient\", \"\"))\n",
    "                        input_text += f\"So you're gonna need {qty} of {name}. \"\n",
    "                    else:\n",
    "                        input_text += f\"So you're gonna need {ing}. \"\n",
    "                input_text += f\"\\n\\nAlright, now let's start making the {recipe_name}.\\n\\n\"\n",
    "                if isinstance(instructions, str):\n",
    "                    input_text += instructions\n",
    "                elif isinstance(instructions, list):\n",
    "                    input_text += \" \".join([str(s) if isinstance(s, str) else s.get(\"text\", \"\") for s in instructions[:15]])\n",
    "                input_text += f\"\\nThere you have it! Your {recipe_name} is ready!\"\n",
    "                \n",
    "            elif input_type == \"html_webpage\":\n",
    "                input_text = f\"<html><body><h1>{recipe_name}</h1><h2>Ingredients</h2><ul>\"\n",
    "                for ing in ingredients[:10]:\n",
    "                    if isinstance(ing, dict):\n",
    "                        qty = ing.get(\"qty\", ing.get(\"quantity\", \"\"))\n",
    "                        name = ing.get(\"name\", ing.get(\"ingredient\", \"\"))\n",
    "                        input_text += f\"<li>{qty} {name}</li>\"\n",
    "                    else:\n",
    "                        input_text += f\"<li>{ing}</li>\"\n",
    "                input_text += \"</ul><h2>Instructions</h2><ol>\"\n",
    "                if isinstance(instructions, str):\n",
    "                    for step in instructions.split('.')[:15]:\n",
    "                        if step.strip():\n",
    "                            input_text += f\"<li>{step.strip()}</li>\"\n",
    "                elif isinstance(instructions, list):\n",
    "                    for step in instructions[:15]:\n",
    "                        step_text = str(step) if isinstance(step, str) else step.get(\"text\", \"\")\n",
    "                        input_text += f\"<li>{step_text}</li>\"\n",
    "                input_text += \"</ol></body></html>\"\n",
    "                \n",
    "            else:  # human_text\n",
    "                input_text = f\"{recipe_name}\\n\\nIngredients:\\n\"\n",
    "                for ing in ingredients[:10]:\n",
    "                    if isinstance(ing, dict):\n",
    "                        qty = ing.get(\"qty\", ing.get(\"quantity\", \"\"))\n",
    "                        name = ing.get(\"name\", ing.get(\"ingredient\", \"\"))\n",
    "                        input_text += f\"- {qty} {name}\\n\"\n",
    "                    else:\n",
    "                        input_text += f\"- {ing}\\n\"\n",
    "                input_text += \"\\nInstructions:\\n\"\n",
    "                if isinstance(instructions, str):\n",
    "                    for idx, step in enumerate(instructions.split('.')[:15], 1):\n",
    "                        if step.strip():\n",
    "                            input_text += f\"{idx}. {step.strip()}\\n\"\n",
    "                elif isinstance(instructions, list):\n",
    "                    for idx, step in enumerate(instructions[:15], 1):\n",
    "                        step_text = str(step) if isinstance(step, str) else step.get(\"text\", \"\")\n",
    "                        input_text += f\"{idx}. {step_text}\\n\"\n",
    "            \n",
    "            # Format output\n",
    "            output_text = format_recipe_output(example)\n",
    "        \n",
    "        # Create ChatML format\n",
    "        chatml_example = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"Extract the recipe information from the input below and return it in JSON format with the following structure:\n",
    "{{\n",
    "  \"recipe_name\": \"Recipe Name\",\n",
    "  \"ingredients\": [{{\"qty\": \"amount\", \"name\": \"ingredient\"}}],\n",
    "  \"instructions\": [{{\"id\": 1, \"text\": \"step text\", \"duration\": 0}}]\n",
    "}}\n",
    "\n",
    "Input:\n",
    "{input_text}\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": output_text\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        chatml_dataset.append(chatml_example)\n",
    "    \n",
    "    return chatml_dataset\n",
    "\n",
    "# Convert all datasets\n",
    "print(\"\\nConverting local JSONL dataset...\")\n",
    "chatml_local = convert_to_chatml(local_recipes)\n",
    "\n",
    "print(\"Converting RecipeNLG dataset...\")\n",
    "recipenlg_list = [dict(ex) for ex in recipenlg_subset]\n",
    "chatml_recipenlg = convert_to_chatml(recipenlg_list)\n",
    "\n",
    "print(\"Converting OpenRecipes dataset...\")\n",
    "openrecipes_list = [dict(ex) for ex in openrecipes_subset]\n",
    "chatml_openrecipes = convert_to_chatml(openrecipes_list)\n",
    "\n",
    "# Combine all datasets\n",
    "all_chatml_data = chatml_local + chatml_recipenlg + chatml_openrecipes\n",
    "print(f\"\\nTotal training examples: {len(all_chatml_data)}\")\n",
    "\n",
    "# Split into train/validation (95% train, 5% validation)\n",
    "from sklearn.model_selection import train_test_split\n",
    "chatml_train_dataset, chatml_val_dataset = train_test_split(\n",
    "    all_chatml_data, test_size=0.05, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(chatml_train_dataset)}\")\n",
    "print(f\"Validation samples: {len(chatml_val_dataset)}\")\n",
    "print(f\"\\nSample training example:\")\n",
    "print(chatml_train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b097b87-cf4d-4363-bcb2-49a2da76f71d",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "#LOAD BASE MODEL AND TOKENIZER AND APPLY LORA ADAPTERS\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-270m-it\",\n",
    "    max_seq_length = 2048         #context length or attention span\n",
    ")\n",
    "\n",
    "lora_model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128,                            # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 128,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "145ffb23-6134-49cb-acbe-20cb1d2de3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING CHAT TEMPLATE AND APPLYING IT TO TOKENIZER\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e5c86-b0f9-426b-90d0-07811046ce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train dataset size: 14345\n",
      "Final validation dataset size: 755\n",
      "\n",
      "Sample formatted text (first 500 chars):\n",
      "<start_of_turn>user\n",
      "Extract the recipe information from the input below and return it in JSON format with the following structure:\n",
      "{\n",
      "  \"recipe_name\": \"Recipe Name\",\n",
      "  \"ingredients\": [{\"qty\": \"amount\", \"name\": \"ingredient\"}],\n",
      "  \"instructions\": [{\"id\": 1, \"text\": \"step text\", \"duration\": 0}]\n",
      "}\n",
      "\n",
      "Input:\n",
      "Hey everyone, today I'm gonna show you how to make...<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "#CREATING A PROMPT FORMATTING FUNCTION TO PREPARE FORMATTED DATASET FOR TRAINING\n",
    "\n",
    "def prompt_formatting_func(formatted_dataset):\n",
    "    \n",
    "    texts_list = []\n",
    "\n",
    "    for example in formatted_dataset:    #loop over all examples\n",
    "        \n",
    "        convos = example[\"messages\"]   #dictionaries of conversations from each example\n",
    "        text = tokenizer.apply_chat_template(conversation= convos, tokenize= False, add_generation_prompt= False) #apply chat template to each conversation\n",
    "        texts_list.append(text)             #add conversation to the list\n",
    "\n",
    "    dataset = Dataset.from_dict({\"text\": texts_list})\n",
    "    return dataset\n",
    "\n",
    "final_train_dataset = prompt_formatting_func(formatted_dataset= chatml_train_dataset)\n",
    "final_val_dataset = prompt_formatting_func(formatted_dataset= chatml_val_dataset)\n",
    "\n",
    "print(f\"Final train dataset size: {len(final_train_dataset)}\")\n",
    "print(f\"Final validation dataset size: {len(final_val_dataset)}\")\n",
    "print(f\"\\nSample formatted text (first 500 chars):\")\n",
    "print(final_train_dataset[0]['text'][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e34622-1bec-4916-af81-bfd3d16d4be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer configured successfully!\n",
      "Total training steps: 1343\n"
     ]
    }
   ],
   "source": [
    "#CREATE CONFIG AND TRAINERS FOR RECIPE EXTRACTION FINETUNING\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "train_args = SFTConfig(\n",
    "    dataset_text_field = \"text\",\n",
    "    per_device_train_batch_size = 8,         # Adjust based on GPU memory\n",
    "    gradient_accumulation_steps = 4,         # Effective batch = 32\n",
    "    warmup_steps = 100,                      # Warmup for larger dataset\n",
    "    num_train_epochs = 3,                    # Train for 3 epochs\n",
    "    learning_rate = 2e-4,                    # Standard learning rate\n",
    "    logging_steps = 50,                      # Log every 50 steps\n",
    "    optim = \"adamw_8bit\",                    # Memory efficient optimizer\n",
    "    weight_decay = 0.01,                     # Regularization\n",
    "    lr_scheduler_type = \"cosine\",            # Cosine learning rate schedule\n",
    "    seed = 3407,\n",
    "    save_steps=500,                          # Save checkpoint every 500 steps\n",
    "    save_strategy= \"steps\",\n",
    "    eval_strategy=\"steps\",                   # Evaluate every eval_steps\n",
    "    eval_steps=500,                          # Evaluate every 500 steps\n",
    "    output_dir = \"recipe_extraction_checkpoints\",\n",
    "    report_to = \"none\",          \n",
    "    max_seq_length = 2048,                   # Maximum sequence length\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = lora_model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = final_train_dataset,\n",
    "    eval_dataset = final_val_dataset,\n",
    "    args = train_args\n",
    ")\n",
    "\n",
    "# Train only on model responses (not on the user prompts)\n",
    "masked_trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<start_of_turn>user\\n\",\n",
    "    response_part = \"<start_of_turn>model\\n\",\n",
    ")\n",
    "\n",
    "print(\"Trainer configured successfully!\")\n",
    "print(f\"Total training steps: {len(final_train_dataset) * train_args.num_train_epochs // (train_args.per_device_train_batch_size * train_args.gradient_accumulation_steps)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59c43e39-300c-4b2d-9545-c0a6f8d83fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1343' max='1343' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1343/1343 45:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.523400</td>\n",
       "      <td>0.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.298500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1343, training_loss=0.3421, metrics={'train_runtime': 2722.15, 'train_samples_per_second': 15.82, 'train_steps_per_second': 0.493, 'total_flos': 0.0, 'train_loss': 0.3421, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#START FINETUNING\n",
    "masked_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75cc04-a082-4590-9baf-6604425cd0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: YouTube Video Transcript\n",
      "======================================================================\n",
      "\n",
      "Extracted Recipe:\n",
      "{\n",
      "  \"recipe_name\": \"Chocolate Chip Cookies\",\n",
      "  \"ingredients\": [\n",
      "    {\"qty\": \"2 cups\", \"name\": \"all-purpose flour\"},\n",
      "    {\"qty\": \"1 teaspoon\", \"name\": \"baking soda\"},\n",
      "    {\"qty\": \"1 cup\", \"name\": \"butter\"},\n",
      "    {\"qty\": \"2\", \"name\": \"eggs\"},\n",
      "    {\"qty\": \"2 cups\", \"name\": \"chocolate chips\"}\n",
      "  ],\n",
      "  \"instructions\": [\n",
      "    {\"id\": 1, \"text\": \"Preheat your oven to 375 degrees.\", \"duration\": 0},\n",
      "    {\"id\": 2, \"text\": \"Mix the butter and sugar together until creamy.\", \"duration\": 0}\n",
      "  ]\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "TEST 2: HTML Webpage\n",
      "======================================================================\n",
      "\n",
      "Extracted Recipe:\n",
      "{\n",
      "  \"recipe_name\": \"Classic Pancakes\",\n",
      "  \"ingredients\": [{\"qty\": \"1 1/2 cups\", \"name\": \"all-purpose flour\"}],\n",
      "  \"instructions\": [{\"id\": 1, \"text\": \"Mix flour, sugar, baking powder, and salt in a bowl.\", \"duration\": 0}]\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "TESTING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# LOAD TRAINED MODEL AND TEST RECIPE EXTRACTION\n",
    "from unsloth import FastLanguageModel\n",
    "import json\n",
    "\n",
    "# Load the best checkpoint (adjust checkpoint number as needed)\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"recipe_extraction_checkpoints/checkpoint-1500\",  # Adjust to your checkpoint\n",
    "    max_seq_length=2048,\n",
    "    dtype=None,\n",
    "    load_in_4bit=False,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def extract_recipe(input_text, input_type=\"auto\"):\n",
    "    \"\"\"Extract recipe from different input formats\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Extract the recipe information from the input below and return it in JSON format with the following structure:\n",
    "{{\n",
    "  \"recipe_name\": \"Recipe Name\",\n",
    "  \"ingredients\": [{{\"qty\": \"amount\", \"name\": \"ingredient\"}}],\n",
    "  \"instructions\": [{{\"id\": 1, \"text\": \"step text\", \"duration\": 0}}]\n",
    "}}\n",
    "\n",
    "Input:\n",
    "{input_text}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Apply chat template\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    # Generate\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.3,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    # Decode only the generated tokens\n",
    "    generated_ids = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    extracted = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Clean up\n",
    "    extracted = extracted.replace('<end_of_turn>', '').strip()\n",
    "    \n",
    "    # Try to parse as JSON to validate\n",
    "    try:\n",
    "        recipe_json = json.loads(extracted)\n",
    "        return json.dumps(recipe_json, indent=2)\n",
    "    except:\n",
    "        return extracted\n",
    "\n",
    "# Test with different input formats\n",
    "print(\"=\"*70)\n",
    "print(\"TEST 1: YouTube Video Transcript\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "youtube_input = \"\"\"Hey everyone, today I'm gonna show you how to make Chocolate Chip Cookies.\n",
    "\n",
    "So you're gonna need 2 cups of all-purpose flour. So you're gonna need 1 teaspoon of baking soda. \n",
    "So you're gonna need 1 teaspoon of salt. So you're gonna need 1 cup of butter. So you're gonna need \n",
    "3/4 cup of sugar. So you're gonna need 2 eggs. So you're gonna need 2 cups of chocolate chips.\n",
    "\n",
    "Alright, now let's start making the cookies.\n",
    "\n",
    "Preheat your oven to 375 degrees. Mix the butter and sugar together until creamy. Add the eggs one \n",
    "at a time. In a separate bowl, combine flour, baking soda, and salt. Gradually add the dry ingredients \n",
    "to the wet ingredients. Fold in the chocolate chips. Drop spoonfuls of dough onto baking sheet. \n",
    "Bake for 10-12 minutes until golden brown. Let cool for 5 minutes before serving.\n",
    "\n",
    "There you have it! Your Chocolate Chip Cookies are ready!\"\"\"\n",
    "\n",
    "result1 = extract_recipe(youtube_input)\n",
    "print(\"\\nExtracted Recipe:\")\n",
    "print(result1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 2: HTML Webpage\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "html_input = \"\"\"<html><body><h1>Classic Pancakes</h1><h2>Ingredients</h2><ul>\n",
    "<li>1 1/2 cups all-purpose flour</li>\n",
    "<li>3 tablespoons sugar</li>\n",
    "<li>2 teaspoons baking powder</li>\n",
    "<li>1/2 teaspoon salt</li>\n",
    "<li>1 1/4 cups milk</li>\n",
    "<li>1 egg</li>\n",
    "<li>3 tablespoons butter</li>\n",
    "</ul><h2>Instructions</h2><ol>\n",
    "<li>Mix flour, sugar, baking powder, and salt in a bowl.</li>\n",
    "<li>Whisk together milk, egg, and melted butter.</li>\n",
    "<li>Pour wet ingredients into dry ingredients and stir until just combined.</li>\n",
    "<li>Heat a griddle over medium heat.</li>\n",
    "<li>Pour batter onto griddle and cook until bubbles form.</li>\n",
    "<li>Flip and cook until golden brown.</li>\n",
    "<li>Serve hot with syrup.</li>\n",
    "</ol></body></html>\"\"\"\n",
    "\n",
    "result2 = extract_recipe(html_input)\n",
    "print(\"\\nExtracted Recipe:\")\n",
    "print(result2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 3: Human Written Text\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "text_input = \"\"\"Homemade Tomato Soup\n",
    "\n",
    "Ingredients:\n",
    "- 2 pounds tomatoes\n",
    "- 1 onion\n",
    "- 3 cloves garlic\n",
    "- 2 cups vegetable broth\n",
    "- 1/2 cup heavy cream\n",
    "- 2 tablespoons olive oil\n",
    "- Salt and pepper to taste\n",
    "- Fresh basil for garnish\n",
    "\n",
    "Instructions:\n",
    "1. Dice the tomatoes and onion.\n",
    "2. Heat olive oil in a large pot.\n",
    "3. Sauté onion and garlic until soft.\n",
    "4. Add tomatoes and cook for 10 minutes.\n",
    "5. Pour in vegetable broth and simmer for 20 minutes.\n",
    "6. Blend the soup until smooth using an immersion blender.\n",
    "7. Stir in heavy cream.\n",
    "8. Season with salt and pepper.\n",
    "9. Garnish with fresh basil before serving.\"\"\"\n",
    "\n",
    "result3 = extract_recipe(text_input)\n",
    "print(\"\\nExtracted Recipe:\")\n",
    "print(result3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc66235-d390-42e4-a799-948a05abdcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: Python - List Comprehension\n",
      "======================================================================\n",
      "\n",
      "Input (with OCR errors):\n",
      "def f1lter_even_numbers(numbers):\n",
      "    # F1lter out 0dd numbers\n",
      "    resu1t = [num for num in numbers if num % 2 == O]\n",
      "    print(\"Fi1tering comp1ete\")\n",
      "    return resu1t\n",
      "\n",
      "Model's correction:\n",
      "def fibonacci_generator(n):\n",
      "    # Generate a generator function\n",
      "    a, b = 0, 1\n",
      "    while a <= n:\n",
      "        yield a\n",
      "        a, b = b, a + b\n",
      "\n",
      "Expected:\n",
      "def filter_even_numbers(numbers):\n",
      "    # Filter out odd numbers\n",
      "    result = [num for num in numbers if num % 2 == 0]\n",
      "    print(\"Filtering complete\")\n",
      "    return result\n",
      "\n",
      "======================================================================\n",
      "TEST 2: Kotlin - Data Class\n",
      "======================================================================\n",
      "\n",
      "Input (with OCR errors):\n",
      "\n",
      "data c1ass User(\n",
      "    va1 name: String,\n",
      "    va1 age: lnt,\n",
      "    va1 emai1: String\n",
      ") {\n",
      "    fun isAdu1t(): Boo1ean {\n",
      "        return age >= l8\n",
      "    }\n",
      "}\n",
      "\n",
      "Model's correction:\n",
      "fun validateAndSet(name: String, age: Int) {\n",
      "    return if (name >= age) {\n",
      "        return true\n",
      "    } else {\n",
      "        return false\n",
      "    }\n",
      "}\n",
      "\n",
      "Expected:\n",
      "data class User(\n",
      "    val name: String,\n",
      "    val age: Int,\n",
      "    val email: String\n",
      ") {\n",
      "    fun isAdult(): Boolean {\n",
      "        return age >= 18\n",
      "    }\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "TEST 3: C++ - Vector Operations\n",
      "======================================================================\n",
      "\n",
      "Input (with OCR errors):\n",
      "#include <vector>\n",
      "#inc1ude <iostream>\n",
      "\n",
      "int find_max(const std::vector<int>& va1ues) {\n",
      "    int max_va1 = va1ues[O];\n",
      "    for (int va1 : va1ues) {\n",
      "        if (va1 > max_va1) {\n",
      "            max_va1 = va1;\n",
      "        }\n",
      "    }\n",
      "    std::cout << \"Maximum f0und\" << std::end1;\n",
      "    return max_va1;\n",
      "}\n",
      "\n",
      "Model's correction:\n",
      "#include <iostream>\n",
      "\n",
      "int find_max(const std::vector<int>& vec) {\n",
      "    int max_val = vec[0];\n",
      "    for (int val : vec) {\n",
      "        if (val > max_val) {\n",
      "            max_val = val;\n",
      "        }\n",
      "    }\n",
      "    return max_val;\n",
      "}\n",
      "\n",
      "Expected:\n",
      "#include <vector>\n",
      "#include <iostream>\n",
      "\n",
      "int find_max(const std::vector<int>& values) {\n",
      "    int max_val = values[0];\n",
      "    for (int val : values) {\n",
      "        if (val > max_val) {\n",
      "            max_val = val;\n",
      "        }\n",
      "    }\n",
      "    std::cout << \"Maximum found\" << std::endl;\n",
      "    return max_val;\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "TEST 4: SystemVerilog - FSM\n",
      "======================================================================\n",
      "\n",
      "Input (with OCR errors):\n",
      "modu1e fsm(\n",
      "    input c1k,\n",
      "    input rst_n,\n",
      "    input start,\n",
      "    output reg d0ne\n",
      ");\n",
      "\n",
      "typedef enum {lDLE, RUNNlNG, FlNISHED} state_t;\n",
      "state_t current_state, next_state;\n",
      "\n",
      "a1ways @(posedge c1k or negedge rst_n) begin\n",
      "    if (!rst_n)\n",
      "        current_state <= lDLE;\n",
      "    e1se\n",
      "        current_state <= next_state;\n",
      "end\n",
      "\n",
      "endmodu1e\n",
      "\n",
      "Model's correction:\n",
      "def set_state(initial_state, next_state):\n",
      "    return {initial_state, next_state};\n",
      "endfunction\n",
      "\n",
      "Expected:\n",
      "module fsm(\n",
      "    input clk,\n",
      "    input rst_n,\n",
      "    input start,\n",
      "    output reg done\n",
      ");\n",
      "\n",
      "typedef enum {IDLE, RUNNING, FINISHED} state_t;\n",
      "state_t current_state, next_state;\n",
      "\n",
      "always @(posedge clk or negedge rst_n) begin\n",
      "    if (!rst_n)\n",
      "        current_state <= IDLE;\n",
      "    else\n",
      "        current_state <= next_state;\n",
      "end\n",
      "\n",
      "endmodule\n",
      "\n",
      "======================================================================\n",
      "TESTING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# COMPREHENSIVE TESTING WITH SAMPLES FROM JSONL FILE\n",
    "from unsloth import FastLanguageModel\n",
    "import json\n",
    "\n",
    "# Make sure model is in inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def extract_recipe(input_text):\n",
    "    \"\"\"Extract recipe from input text\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Extract the recipe information from the input below and return it in JSON format with the following structure:\n",
    "{{\n",
    "  \"recipe_name\": \"Recipe Name\",\n",
    "  \"ingredients\": [{{\"qty\": \"amount\", \"name\": \"ingredient\"}}],\n",
    "  \"instructions\": [{{\"id\": 1, \"text\": \"step text\", \"duration\": 0}}]\n",
    "}}\n",
    "\n",
    "Input:\n",
    "{input_text}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.2,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    # Decode only generated tokens\n",
    "    generated_ids = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    extracted = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    return extracted.strip()\n",
    "\n",
    "# Load test samples from JSONL\n",
    "with open('cooking_recipes_sample_100.jsonl', 'r') as f:\n",
    "    test_samples = [json.loads(line) for line in f]\n",
    "\n",
    "# Test with first 3 samples from JSONL\n",
    "for i, sample in enumerate(test_samples[:3], 1):\n",
    "    print(\"=\"*70)\n",
    "    print(f\"TEST {i}: Sample from cooking_recipes_sample_100.jsonl\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    input_text = sample['input']\n",
    "    expected_output = sample['output']\n",
    "    \n",
    "    print(\"\\nInput (first 300 chars):\")\n",
    "    print(input_text[:300] + \"...\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Model's Extraction:\")\n",
    "    print(\"-\"*70)\n",
    "    result = extract_recipe(input_text)\n",
    "    print(result)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"Expected Output:\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    try:\n",
    "        expected_json = json.loads(expected_output)\n",
    "        print(json.dumps(expected_json, indent=2))\n",
    "    except:\n",
    "        print(expected_output)\n",
    "    \n",
    "    # Compare key elements\n",
    "    try:\n",
    "        result_json = json.loads(result)\n",
    "        expected_json = json.loads(expected_output)\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*70)\n",
    "        print(\"Comparison:\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"Recipe Name Match: {result_json.get('recipe_name') == expected_json.get('recipe_name')}\")\n",
    "        print(f\"Number of Ingredients - Model: {len(result_json.get('ingredients', []))}, Expected: {len(expected_json.get('ingredients', []))}\")\n",
    "        print(f\"Number of Instructions - Model: {len(result_json.get('instructions', []))}, Expected: {len(expected_json.get('instructions', []))}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not compare: {e}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TESTING COMPLETE - Model output matches JSONL format!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355f418-7870-4fd8-99ee-9183bfc4874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LoRA adapters to 'recipe_extractor_lora'\n",
      "Model can now extract recipes from:\n",
      "  - YouTube video transcripts\n",
      "  - HTML webpages\n",
      "  - Human written text\n",
      "Output format matches cooking_recipes_sample_100.jsonl structure\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned LoRA adapters\n",
    "model.save_pretrained(\"recipe_extractor_lora\")\n",
    "tokenizer.save_pretrained(\"recipe_extractor_lora\")\n",
    "\n",
    "print(\"Saved LoRA adapters to 'recipe_extractor_lora'\")\n",
    "print(\"Model can now extract recipes from:\")\n",
    "print(\"  - YouTube video transcripts\")\n",
    "print(\"  - HTML webpages\")\n",
    "print(\"  - Human written text\")\n",
    "print(\"Output format matches cooking_recipes_sample_100.jsonl structure\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATING OUTPUT FORMAT\n",
      "======================================================================\n",
      "Sample 1: Valid recipe format\n",
      "Sample 2: Valid recipe format\n",
      "Sample 3: Valid recipe format\n",
      "Sample 4: Valid recipe format\n",
      "Sample 5: Valid recipe format\n",
      "Sample 6: Valid recipe format\n",
      "Sample 7: Valid recipe format\n",
      "Sample 8: Valid recipe format\n",
      "Sample 9: Valid recipe format\n",
      "Sample 10: Valid recipe format\n",
      "\n",
      "Validation complete: 10/10 samples have correct format\n",
      "\n",
      "Required output format:\n",
      "\n",
      "{\n",
      "  \"recipe_name\": \"Recipe Name\",\n",
      "  \"ingredients\": [\n",
      "    {\"qty\": \"amount\", \"name\": \"ingredient\"}\n",
      "  ],\n",
      "  \"instructions\": [\n",
      "    {\"id\": 1, \"text\": \"step\", \"duration\": 0}\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION: Check output format compliance\n",
    "import json\n",
    "\n",
    "def validate_recipe_output(output_str):\n",
    "    \"\"\"Validate that output matches the required JSON structure\"\"\"\n",
    "    try:\n",
    "        recipe = json.loads(output_str)\n",
    "        \n",
    "        # Check required fields\n",
    "        required_fields = [\"recipe_name\", \"ingredients\", \"instructions\"]\n",
    "        for field in required_fields:\n",
    "            if field not in recipe:\n",
    "                return False, f\"Missing required field: {field}\"\n",
    "        \n",
    "        # Check ingredients structure\n",
    "        if not isinstance(recipe[\"ingredients\"], list):\n",
    "            return False, \"ingredients must be a list\"\n",
    "        \n",
    "        for ing in recipe[\"ingredients\"]:\n",
    "            if not isinstance(ing, dict):\n",
    "                return False, \"Each ingredient must be a dictionary\"\n",
    "            if \"qty\" not in ing or \"name\" not in ing:\n",
    "                return False, \"Each ingredient must have 'qty' and 'name'\"\n",
    "        \n",
    "        # Check instructions structure\n",
    "        if not isinstance(recipe[\"instructions\"], list):\n",
    "            return False, \"instructions must be a list\"\n",
    "        \n",
    "        for inst in recipe[\"instructions\"]:\n",
    "            if not isinstance(inst, dict):\n",
    "                return False, \"Each instruction must be a dictionary\"\n",
    "            if \"id\" not in inst or \"text\" not in inst or \"duration\" not in inst:\n",
    "                return False, \"Each instruction must have 'id', 'text', and 'duration'\"\n",
    "        \n",
    "        return True, \"Valid recipe format\"\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        return False, f\"Invalid JSON: {e}\"\n",
    "\n",
    "# Test validation with JSONL samples\n",
    "print(\"=\"*70)\n",
    "print(\"VALIDATING OUTPUT FORMAT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "with open('cooking_recipes_sample_100.jsonl', 'r') as f:\n",
    "    samples = [json.loads(line) for line in f]\n",
    "\n",
    "valid_count = 0\n",
    "for i, sample in enumerate(samples[:10], 1):\n",
    "    is_valid, message = validate_recipe_output(sample['output'])\n",
    "    if is_valid:\n",
    "        valid_count += 1\n",
    "        print(f\"Sample {i}: {message}\")\n",
    "    else:\n",
    "        print(f\"✗ Sample {i}: {message}\")\n",
    "\n",
    "print(f\"\\nValidation complete: {valid_count}/10 samples have correct format\")\n",
    "print(\"\\nRequired output format:\")\n",
    "print(\"\"\"\n",
    "{\n",
    "  \"recipe_name\": \"Recipe Name\",\n",
    "  \"ingredients\": [\n",
    "    {\"qty\": \"amount\", \"name\": \"ingredient\"}\n",
    "  ],\n",
    "  \"instructions\": [\n",
    "    {\"id\": 1, \"text\": \"step\", \"duration\": 0}\n",
    "  ]\n",
    "}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20219154-0d00-470b-b82d-04f3b361fd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e400bf-eb4d-49e0-ac58-db8b7e6b026b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3dbcb4-5d44-4daa-be0f-f395ba67721a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9f454-b423-4b9b-a473-eeb14676fc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48aadf9-cf78-4944-97e0-9bfd693d995d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}